version: '3.8'

volumes:
  llama-api-models:

services:
  llama-api:
    image: cosogi/llama-api:latest
    cap_add:
      - IPC_LOCK
      - SYS_NICE
      - SYS_RESOURCE
    entrypoint: ["python3", "-m", "main", "--port", "8000"]
    environment:
      - FORCE_CUDA=1
      - LLAMA_API_MAX_WORKERS=1
      - LLAMA_API_API_KEY=
    volumes:
      - llama-api-models:/app/models
      - ./model_definitions.py:/app/model_definitions.py
    ports:
      - 8000:8000
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            capabilities: [gpu]